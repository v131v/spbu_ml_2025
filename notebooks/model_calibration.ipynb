{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bb40f-5249-4f5e-82ec-369d02f54c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from scipy.special import expit\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "SEED = 314159\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "\n",
    "data_path = \"D:\\data\\ml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ab494-a2fa-4850-a22e-90958e27845b",
   "metadata": {},
   "source": [
    "# Калибровка вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595a52f-a556-4aee-9b7c-4d1f5299cc5d",
   "metadata": {},
   "source": [
    "Часто при обучении моделей для бинарной классификации хочется получать не только предсказанную метку класса, но и вероятность положительного класса. Предсказанная вероятность может служить как мера уверенности нашего алгоритма. Также это позволяет сравнивать две модели, у которых одинаковые метрики точности. Этот тип метрик конкретно используется в высокорисковых приложениях, позволяя нам не рассматривать результаты модели как реальные вероятности, а вместо этого выходить за рамки необработанных результатов и предотвращать плохое принятие решений или ложную интерпретацию.\n",
    "\n",
    "В задаче бинарной классификации откалиброванным алгоритмом называют такой алгоритм, для которого доля положительных примеров (на основе реальных меток классов) для предсказаний в окрестности произвольной вероятности $\\hat p$ совпадает с этим значением $p$. Например, если взять объекты, для которых предсказанные вероятности близки к 0.7, то окажется, что среди них 70\\% принадлежат положительному классу.\n",
    "На математическом языке это выглядит так: если $\\hat p$  — предсказанная вероятность класса 1, то $P(y=1|q(x_i)=\\hat p)=\\hat p$.\n",
    "\n",
    "Однако некоторые алгоритмы не выдают корректные вероятности классов. В таком случае вероятности модели нужно калибровать.\n",
    "\n",
    "Для визуализации откалиброванности алгоритма можно построить калибровочную кривую. На этой кривой абсцисса точки соответствуют значению $p$ (предсказаний алгоритма), а ордината соответствует доле примеров, для которых алгоритм предсказал вероятность, близкую к $p$. В идеальном случае эта кривая совпадает с прямой $y = x$. \n",
    "\n",
    "Чаще всего  $\\hat p$ - это какие-то вещественные числа, которые будут разными для разных $y_i$. Для того, чтобы оценить именно вероятности, отрезок $[0, 1]$ можно разбить на бины, и для каждого бина вычислить долю класса 1 и,соответственно, среднюю предсказанную вероятность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e50e1c-6658-45f8-b4fe-ff342ac1fe62",
   "metadata": {},
   "source": [
    "Пример диаграммы калибровки: \n",
    "\n",
    "![calib_1](../additional_materials/images/calib_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5403e26e-5b24-4b2c-b0b2-1b2ed93234de",
   "metadata": {},
   "source": [
    "У идеально откалиброванной модели зеленая и розовая линии должны совпадать. Однако в нашем случае модель завышает свою оценку. Как отделить положительные примеры от отрицательных (дать дискретный класс)? Обычно пользуются порогом (логично сделать 0.5). Но нам придется сдвинуть порог вправо - так, чтобы разбить зеленый график пополам по вертикали.\n",
    "\n",
    "Часто картинка иная. В таком случае говорят о слишком увернной модели (overconfident) или неуверенной (underconfident). В первом случае молдель предсказывает вероятности ближе к экстремальным, ченм стоит (0.1 вместо 0.2 и 0.9 вместо 0.1), во втором же наоборот, сводит все вероятности к центру интервала.\n",
    "\n",
    "![calib_2](../additional_materials/images/calib_2.png)\n",
    "\n",
    "Часто слишком большой уверенностью грешат нейросети, так как их учат именно на метках классов. Способ с этим бороться - Label smoothing, когда вместо метки класса модели дают слегка сглаженное значение (0.9 вместо 1, и т.д.). Альтернативный путь - hard samples mining, когда мы заставляем модель больше обращать внимания на объекты ближе к границе разделения.\n",
    "\n",
    "Второй же случай возникает, если мы, наоборот, слишком сильно уделяем внимание границе. Это часто происходит в SVM или бэггинге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bee778-eac7-4ea1-8486-134ea8c9f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path + '/' + 'riceClassification.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf004334-4951-4dea-a18d-3317029c4fe1",
   "metadata": {},
   "source": [
    "Отмасштабируем данные и подготовим трейн и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532257e-529f-4b27-9f72-881fe96adc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['id', 'Class'])\n",
    "y = data.Class\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=999)\n",
    "scaler = StandardScaler().fit(X_train, y_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f03efc-b826-4adc-b164-3630ad053355",
   "metadata": {},
   "source": [
    "**Задание**: Оцените сбалансированность классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ed551-c01a-4766-8561-92ab38652c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30f8348-aaf3-4592-b9f4-e8b441819aea",
   "metadata": {},
   "source": [
    "Обучим метод опорных векторов (SVC — Support Vector Classification) и логистическую регрессию, в качестве метрики возьмем ROC-AUC. \n",
    "В качестве скоров будем рассматривать выход decision_function. Этот метод возвращает confidence score для семплов и пропорционален расстоянию до разделяющей гиперплоскости, взятого со знаком. Он вернет матрицу размера (n_samples, n_classes). В бинарном случае, будет возвращен скор для класса 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7309a-687e-406b-99d6-ad58b8331930",
   "metadata": {},
   "source": [
    "Вопрос: Какая формула для decision function у логистической регрессии?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ebf0a-a376-4146-859e-242237b9374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(max_iter=100000, C=0.1).fit(X_train, y_train)\n",
    "svc_pred = svc.decision_function(X_test)\n",
    "print('SVC ROC-AUC:', roc_auc_score(y_test, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6165f5-f651-4c6d-8336-8ab6cd428aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df358e4-bc54-4f69-a90d-42cb1b551f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59fb63-3840-4cf8-9d6c-506e6ea00d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVC ROC-AUC (on predictions):', roc_auc_score(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff01fcf-7184-4d11-b188-6704c611d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# предскажите вероятности с помощью SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0148867-65d6-4507-b382-369ed1595a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=100000, C=0.1).fit(X_train, y_train)\n",
    "lr_pred = lr.decision_function(X_test)\n",
    "print('Logistic regression ROC-AUC:', roc_auc_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8724d-02cc-48b8-91d5-00a2aea2d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740fe0f-5299-4463-aab3-021cecba4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501fb5c7-ecff-4b8f-8984-eb9f1a2cafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b01c1c-2c1e-4814-ba25-f2f99c989d1d",
   "metadata": {},
   "source": [
    "Суда по метрике, мы практически идеально предсказываем класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72876079-556e-41f7-aa1f-bb8825b3b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "axs[0].hist(svc_pred, bins=20, color='green', density='True')\n",
    "axs[1].hist(lr_pred, bins=20, color='magenta', density='True')\n",
    "\n",
    "axs[0].set_title('SVC')\n",
    "axs[1].set_title('Logistic regression')\n",
    "\n",
    "plt.suptitle('Outputs distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694d50e-e01a-4037-aafc-c465d91b0b31",
   "metadata": {},
   "source": [
    "Мы видим, что скоры могут принимать любые вещественные значения. Но для оценивания вероятностей нам нужно перевести их в промежуток \n",
    "$[0,1]$. С логистической регрессией несложно: можно добавить сигмоиду или софтмакс, ведь модель и обучалась так, чтобы $\\sigma (W^Tx)$\n",
    " приближало вероятности. Для SVC у нас нет такой опции, поэтому воспользуемся масштабированием через минимум-максимум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce626d-656b-4274-9fb2-9438b9b60e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = (svc_pred - svc_pred.min()) / (svc_pred.max() - svc_pred.min())\n",
    "lr_pred = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a91da-95b8-4b3c-a3c7-03cab66ecea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "svc_true_prob, svc_pred_prob = calibration_curve(y_test, svc_pred, n_bins=15)\n",
    "lr_true_prob, lr_pred_prob = calibration_curve(y_test, lr_pred, n_bins=15)\n",
    "\n",
    "plt.plot(svc_pred_prob, svc_true_prob, label='SVC', color='blue')\n",
    "plt.plot(lr_pred_prob, lr_true_prob, label='LR', color='orange')\n",
    "plt.plot([0, 1], [0, 1], label='Perfect', linestyle='--', color='green')\n",
    "\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd984a9d-5e21-498e-a1eb-87f0d25c62a9",
   "metadata": {},
   "source": [
    "Мы видим, что кривая для логистической регрессии неплохо приближает диагональ. С SVC все гораздо хуже. Но попробуем откалибровать модели разными способами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a4445-5e9e-41a6-8471-632bcab4309f",
   "metadata": {},
   "source": [
    "**Задание**: Постройте гистограмму предсказанных вероятностей для двух классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e62b1-e495-4a9d-8e29-9967c779242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0990d-d653-42d4-acfd-542971f7a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Plot preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878526a-5a10-41f8-92fd-98285778db2e",
   "metadata": {},
   "source": [
    "# Калибровка Платта\n",
    "Пусть наш алгоритм выдаёт значения $f(x)$ (могут не быть вероятностями). Тогда итоговая вероятность строится как:\n",
    "\n",
    "$$P(y = 1 | x) = \\frac{1}{1+\\exp (af(x) + b)},$$\n",
    "\n",
    "где $a, b$ -- скалярные параметры. Эти параметры настраиваются методом максимума правдоподобия (минимизируя логистическую функцию потерь) на отложенной выборке. Также Платт предложил настраивать параметры на обучающей выборке базовой модели, а для избежания переобучения изменить метки объектов на следующие значения:\n",
    "\n",
    "$$t_{+} = \\frac{N_{+} + 1}{N_{-} + 2}$$ для положительных примеров и\n",
    "\n",
    "$$t_{-} = \\frac{1}{N_{-} + 2}$$ для отрицательных.\n",
    "\n",
    "Калибровку Платта можно представить как применения логистической регрессии поверх предсказаний другого алгоритма с отключенной регуляризацией. \n",
    "Калибровка Платта неплохо справляется с SVM, но для более хитрых классификаторов может спасовать. В целом, можно показать, что этот метод хорошо работает, если для каждого из истинных классов предсказанные вероятности распределены нормально с одинаковыми дисперсиями (подробнее [здесь](https://research-information.bris.ac.uk/ws/portalfiles/portal/154625753/Full_text_PDF_final_published_version_.pdf)). \n",
    "\n",
    "Вообще эта калибровка относится к большой группе параметрических методов калибрации, туда же относится бета-калибрация (в предположении бета-распределения) или калибрация Дирихле (для мультикласса). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173b385-6391-4699-80b1-26359cf8732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_svc = CalibratedClassifierCV(svc, cv=3, method='sigmoid').fit(X_train, y_train)\n",
    "sigmoid_svc_pred = sigmoid_svc.predict_proba(X_test)[:, 1]\n",
    "print('SVC ROC-AUC:', roc_auc_score(y_test, sigmoid_svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c0ee4-73c7-4ad4-9e74-18b462d48c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_lr = # YOUR CODE: make the same for LR\n",
    "print('Logistic regression ROC-AUC:', roc_auc_score(y_test, sigmoid_lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1d1cf-111d-40e5-b3fa-baa52943f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Plot calibration  curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be9b2d-26aa-4f16-af65-34e06c400340",
   "metadata": {},
   "source": [
    "Как мы видим, калибровка Платта действительно улучшила вероятности, который получаются у SVC. При этом кривая для логистической регрессии практически не сдвигается. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb6dc5-12bc-4f4f-b73e-164b7fe2ef4b",
   "metadata": {},
   "source": [
    "# Изотоническая регрессия\n",
    "В этом методе также строится отображение из предсказаний модели в откалиброванные вероятности. Для этого используем изотоническую функцию (неубывающая кусочно-постоянная функция), в которой $x$ -- выходы нашего алгоритма, а $y$ -- целевая переменная. \n",
    "\n",
    "Мы хотим найти такую функцию $m(t)$: $P(y = 1 | x) = m(f(x))$. Она настраивается под квадратичную ошибку:\n",
    "\n",
    "$$m = \\arg \\min_{z} \\sum (y_i - z(f(x_i))^2,$$\n",
    "\n",
    "с помощью специального алгоритма (Pool-Adjacent-Violators Algorithm), изучать который в этом курсе мы не будем.\n",
    "\n",
    "В результате калибровки получаем надстройку над нашей моделью, которая применяется поверх предсказаний базовой модели. В случае мультиклассовой классификации каждый класс калибруется отдельно против остальных (one-versus-all), вероятности при предсказании нормируются.\n",
    "\n",
    "Этот метод склонен к переобучению, поэтому его рекомендуется применять только для больших выборок.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65170a7-6760-4c70-ae08-51b71e32e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotonic_svc = CalibratedClassifierCV(svc, cv=3, method='isotonic').fit(X_train, y_train)\n",
    "isotonic_svc_pred = isotonic_svc.predict_proba(X_test)[:, 1]\n",
    "print('SVC ROC-AUC:', roc_auc_score(y_test, isotonic_svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fd42d-e837-48a5-807e-db8544af97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Make the same for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b7cd8-223e-4241-9553-19d52968636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: Make the calibration plots for new models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fa217-6865-4699-a59c-15f1668950ed",
   "metadata": {},
   "source": [
    "Изотоническая регрессия немного подпортила кривую калибрации для линейной регрессии. Судя по всему, этот метод немного переобучился, хоть у нас и есть достаточно большая выборка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52abc31-0546-4950-983a-cc31de7c6812",
   "metadata": {},
   "source": [
    "## Мультикласс\n",
    "У нас есть как минимум три варианта определить, что означает мультиклассовая калиброванность. Например, по мере увеличения строгости:\n",
    "1) Учитывать только самую высокую вероятность. Для него мы требуем, чтобы среди всех случаев, где вероятность наиболее вероятного класса прогнозируется как $c$, ожидаемая точность была бы $c$. $P(Y=i|\\hat p_i(x)=q_i)=q_i, i=\\arg\\max_j \\hat p_j (X)$\n",
    "2) Учитывать маргинальные вероятности. Тут мы хотим, чтобы все one-vs-rest вероятности были откалиброваны: $P(Y=i|\\hat p_i(x)=q_i)=q_i, i=1...k$.\n",
    "3) Учитывать весь вектор вероятностей. Т.е. чтобы пропорции классов для семплов с определенным вектором предсказаний былит такие же, как и весь вектор предсказаний:  $P(Y=i|\\hat p(x)=q)=q_i, i=1...k$. \n",
    "   \n",
    "Чаще всего используется определение слабой калиброванности (1). Однако, в случае чувствительной к стоимости постановки задачи оно может быть слишком слабым.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b56b13-cee4-4717-942c-f880dfc0c601",
   "metadata": {},
   "source": [
    "## Оценка качества калибровки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e65780-ccba-44fb-bd97-59132ea36d97",
   "metadata": {},
   "source": [
    "Мы что-то поняли по графикам, но как оценить численно улучшение предсказания вероятностей? Для этого есть свои метрики.\n",
    "\n",
    "**Maximum calibration error**. Самый простой способ, впрочем — он наследник идеи с калибровочной кривой. А именно, разобьём отрезок \n",
    "$[0,1]$ на бины $B_1, B_2, ..., B_k$ по предсказанным вероятностям и вычислим следующее:\n",
    "$$ \\max_{j=1,..,k}|{\\overline y(B_k) - \\overline q (B_k) }|$$\n",
    "Иными словами, посчитаем максимальную разницу между точностью и уверенностью модели в бинах.\n",
    "\n",
    "**Expected Calibration Error (ECE)** считает среднюю разницу: $$ \\sum^k_{j=1}{{\\|B_j\\|}\\over{N}}{| {\\overline y(B_k) - \\overline q (B_k) }|},$$\n",
    "где $\\|B_j\\|$ - число семплов в бине.\n",
    "\n",
    "Проблема этих способов в том, что мы можем очень по-разному предсказывать в каждом из бинов вероятности (в том числе константой) без ущерба для метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c7517-478c-4b9e-9b1d-ea12fa9e260b",
   "metadata": {},
   "source": [
    "Применим метрику калибрации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e9725-1b66-4907-9469-ce90902769f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycalib.metrics import binary_ECE\n",
    "\n",
    "print(\"Platt:\")\n",
    "print('SVC binary-ECE = ', binary_ECE(y_test, sigmoid_svc_pred ))\n",
    "print('Linear binary-ECE = ', binary_ECE(y_test, sigmoid_lr_pred))\n",
    "\n",
    "print(\"Isotonic:\")\n",
    "print('SVC binary-ECE = ', binary_ECE(y_test,isotonic_svc_pred ))\n",
    "print('Linear binary-ECE = ', binary_ECE(y_test, isotonic_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10d9cd-c52e-49e4-8e32-23f2daded62c",
   "metadata": {},
   "source": [
    "**Задание**: Посчитайте метрику для неоткалиброванного классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c047b-9eff-4593-b398-0a19375b2c15",
   "metadata": {},
   "source": [
    "**Вопрос**: Как можно адаптировать MCE/ECE для мультиклассовой задачи? Напишите формулы.\n",
    "*Ответ*: использовать выигравший класс. Можно сделать бинарные есе для всех классов и потом усреднить по классам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3ea98-96ea-42f3-aedc-bdd82d049c61",
   "metadata": {},
   "source": [
    "В случае мультикласса, у нас возникает несколько сложностей: во-первых, в случае большого числа классов число бинов будет очень большим, при этом многие будут пустыми. Да и само определение реальной ECE пока не сделано. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c24643-9b58-46aa-8320-4a266027f01d",
   "metadata": {},
   "source": [
    "Можно посчитать калиброванность и на уровне семплов.\n",
    "\n",
    "**Brier score.** Тоже одна из популярных метрик, которая попросту измеряет разницу между предсказанными вероятностями и $ y_i $ (обратите внимание, что $ y_i $  - это либо 0, либо 1):\n",
    "$$ \\sum^N_{i=1}(y_i - q (x_i))^2,$$ \n",
    "для бинарного случая, и\n",
    "$$ {1 \\over N} \\sum^N_{n=1}\\sum^K_{j=1} (I(y_n=j) - q_{nj})^2,$$ \n",
    "для мультикласса.\n",
    "\n",
    "**Вопрос**: Какое значение соответствует лучшей калибрации? Какие максимальные и минимальные значения он можеит принимать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77618e86-41c7-4e9c-be09-c373f05f436d",
   "metadata": {},
   "source": [
    "Также можно использовать log-loss:\n",
    "$$ {-1\\over N} {\\sum^N_{n=1}\\sum^K_{j=1}I(y_n=j)log(q_{n,j})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa6e27-68da-462a-a8ef-f788333c8c79",
   "metadata": {},
   "source": [
    "Для достаточно гладких классификатора и датасета brier score и log-loss будут адекватными средствами оценки, но если нет — возможно всякое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142af3a5-6bfa-4137-814f-3e074467f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycalib.metrics import brier_score\n",
    "\n",
    "print(\"Platt:\")\n",
    "print('SVC brier score = ', brier_score(y_test, sigmoid_svc_pred ))\n",
    "print('Linear brier score  = ', brier_score(y_test, sigmoid_lr_pred))\n",
    "\n",
    "print(\"Isotonic:\")\n",
    "print('SVC brier score  = ', brier_score(y_test,isotonic_svc_pred ))\n",
    "print('Linear brier score = ', brier_score(y_test, isotonic_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921cd4c9-d3ca-4955-8343-2d379cadd4ba",
   "metadata": {},
   "source": [
    "**Задание**: Посчитайте метрику для неоткалиброванного классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02206114-35cc-4b86-9d06-891688889ac2",
   "metadata": {},
   "source": [
    "Итак, мы откалибровали наши классификаторы. Теперь мы можем оценить, как поменяются метрики после этого. Так, по идее точность, f1 не должны сильно поменяться, так как вблизи от границы разделения вероятности не должны сильно измениться. Так ли это?\n",
    "Теперь **вопрос**: Изменится ли ппосле калибрации ROC-AUC и как? Можете ли вы ответить на вопрос без измерений?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d2970-5eb1-4691-9419-2e2f8eeae97d",
   "metadata": {},
   "source": [
    "**Задание**: Обучите дерево решений и случайный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48349ca-9d2a-4d88-a3d9-d56a3e9a70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: \n",
    "# 1) train DT, RF\n",
    "# 2) output scores for these models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c45b0-5ca9-4923-914a-f21b207977ff",
   "metadata": {},
   "source": [
    "**Задание**: Откалибройте изотоническим методом. Постройте калибровочные кривые для классификаторов, до и после калибровки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba3ee5-9c59-4d57-8406-58ee4501744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: \n",
    "# 1) make isotonic calibration\n",
    "# 2) make sigmoid calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4cbc7-0c70-49ae-a408-fe606ca6c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE: \n",
    "# plot results of calibration (calibration curves)\n",
    "# optional: plot non-calibrated curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497839b-fc85-478d-a653-a82a12f22df2",
   "metadata": {},
   "source": [
    "ВОпрос: Какой вывод можно сделать из графиков?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e70e7c-f468-4657-ad7f-d9674236daab",
   "metadata": {},
   "source": [
    "**Задание**: Какой из классификаторов в итоге лучше откалиброван (среди всех)? Покажите в сравнении. Какой вы выберете далее?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25647811-8147-4c52-82ff-1ec106ffa9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
