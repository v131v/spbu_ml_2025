{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contemporary-rouge",
   "metadata": {},
   "source": [
    "\n",
    "# Случайный лес\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d7ea4-7669-4cba-93ab-7bbf6a2e670d",
   "metadata": {},
   "source": [
    "В данном случае мы говорим об **ансамбле** решающих деревьев (отсюда и слово лес). \n",
    "В обычных деревьях для задачи классификации в листях деревьев лежит класс. Для задачи регресии в листях лежит среднее значение ответов для всех объектов. \n",
    "Чтобы получить результат работы леса, ответы отдельных деревьев должны быть как-то аггрегированы. Вопрос: Как это можно удобно сделать?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e64f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:49:31.201889Z",
     "start_time": "2023-05-10T11:49:30.519955Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_path = r\"C:\\Users\\nikol_ri8fhbe\\Documents\\ml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-recorder",
   "metadata": {},
   "source": [
    "## Решающее дерево\n",
    "Начнём с построения решающего дерева. Для демонстрации используем упрощенный датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-willow",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:49:31.346252Z",
     "start_time": "2023-05-10T11:49:31.338141Z"
    }
   },
   "outputs": [],
   "source": [
    "california = fetch_california_housing()\n",
    "california_X = pd.DataFrame(data=california.data, columns=california.feature_names)\n",
    "california_Y = california.target\n",
    "print(f\"X shape: {california_X.shape}, Y shape: {california_Y.shape}\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    california_X, california_Y, test_size=0.3, random_state=123, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa58dbce-0101-477f-aec6-87a4b90a156b",
   "metadata": {},
   "source": [
    "**Задание**: Ниже пример подготовки нашего датасета с домами. Проведите все действия этого ноутбука и для него. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eeaf67d-2564-4976-bfc6-e4ebb49efa12",
   "metadata": {},
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b101319e-5516-40a3-a434-49e157f4b44f",
   "metadata": {},
   "source": [
    "train_df = pd.read_csv(cfg['house_pricing']['train_dataset'])\n",
    "train_df.head()\n",
    "train_df[\"Exterior2nd\"] = train_df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n",
    "    # Some values of GarageYrBlt are corrupt, so we'll replace them\n",
    "    # with the year the house was built\n",
    "train_df[\"GarageYrBlt\"] = train_df[\"GarageYrBlt\"].where(train_df.GarageYrBlt <= 2010, train_df.YearBuilt)\n",
    "    # Names beginning with numbers are awkward to work with\n",
    "train_df.rename(columns={\n",
    "        \"1stFlrSF\": \"FirstFlrSF\",\n",
    "        \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "        \"3SsnPorch\": \"Threeseasonporch\",\n",
    "        }, inplace=True,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df.drop(\"SalePrice\", axis=1),train_df[\"SalePrice\"],  test_size=0.3, random_state=123, shuffle=True\n",
    ")\n",
    "\n",
    "cat_сols = X_train.select_dtypes(include=['object']).columns\n",
    "count_encoder = ce.CountEncoder()\n",
    "X_train = count_encoder.fit_transform(X_train, y_train)\n",
    "X_test = count_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-jacksonville",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:49:31.459233Z",
     "start_time": "2023-05-10T11:49:31.346360Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# TODO: обучите решающее дерево без ограничений на тренировочной выборке\n",
    "tree = DecisionTreeRegressor(max_depth=9)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# TODO: рассчитайте MSE на тренировочной и тестовой выборках\n",
    "print(f\"MSE on train set: {mean_squared_error(y_train, tree.predict(X_train)):.2f}\")\n",
    "print(f\"MSE on test set: {mean_squared_error(y_test, tree.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11287a4d-bd15-4ada-a9fe-3919f54251fa",
   "metadata": {},
   "source": [
    "Мы видим, что наше дерево сильно переобучилось - оно идеально предсказывает значения на трейне и довольно плохо - на тесте. Заглянем в эту проблему чуть глубже. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa34e9-4180-4f8b-8415-7ba3820d30dd",
   "metadata": {},
   "source": [
    "Среднеквадратичный риск на фиксированной выборке X можно расписать как \n",
    "$$E = Var(h) + Bias^2(h) + Noise(y)$$\n",
    "Здесь $Bias^2(h) = E_x[(\\overline{h}(X) - \\overline{y}(X))^2]$ показывает, насколько средняя модель отклонится от матожидания таргета (идеальной модели). \n",
    "$Var(h) = E_{x,D}[(h(X, D) - \\overline{h}(X))^2]$ - показывает разброс обученных моделей относительно среднего ответа. \n",
    "$Noise(y) = E_{x,y}[(\\overline{y}(X) - Y)^2]$ - дисперсия самого таргета при фиксированном x. Это неустранимая ошибка, которой соответствует самый идеальный прогноз.\n",
    "Смещение показывает, насколько хорошо можно с помощью данного семейства моделей приблизиться к оптимальной модели. Как правило, оно маленькое у сложных семейств и большое у относительно простых. \n",
    "\n",
    "Дисперсия показывает, насколько будет изменяться предсказание в зависимости от выборки - то есть насколько ваше семейство склонно к переобучению. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271e890-842b-4592-a8bb-31f0e673f7e4",
   "metadata": {},
   "source": [
    "На нашем примере с домами посмотрим, какие bias и variance имеет наше дерево. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-yemen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:49:47.314276Z",
     "start_time": "2023-05-10T11:49:31.461093Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "# TODO: выведите среднее смещение и среднюю дисперсию модели на тестовой выборке\n",
    "avg_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "    tree,\n",
    "    np.array(X_train),\n",
    "    np.array(y_train),\n",
    "    np.array(X_test),\n",
    "    np.array(y_test),\n",
    "    loss=\"mse\",\n",
    ")\n",
    "print(f\"Average test loss: {avg_loss:.2f}\")\n",
    "print(f\"Average test bias: {avg_bias:.2f}\")\n",
    "print(f\"Average test variance: {avg_var:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6365-05e0-4628-8a98-8b6943f729dd",
   "metadata": {},
   "source": [
    "Декомпозиция довольно долгая, так как для вычисленя средних мы много раз (по умолчанию, 200) строим подвыборки тестового сета. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-murder",
   "metadata": {},
   "source": [
    "Мы видим, что у нашего дерева высокая дисперсия и низкое смещение. Постараемся исправить это. Один из способов борьбы с переобучением – построение композиций моделей. На этом семинаре мы рассмотрим построение композиций при помощи бэггинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc9974-47ea-457e-be34-572d537087cd",
   "metadata": {},
   "source": [
    "**Задание:**  Постройте графики зависимости смещения и разброса относительно глубины дерева, обученного на этом датасете.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-personal",
   "metadata": {},
   "source": [
    "### Случайный лес\n",
    "\n",
    "При построении каждого дерева в бэггинге в ходе создания очередного узла будем выбирать случайный набор признаков, на основе которых производится разбиение. В результате такой процедуры мы уменьшим корреляцию между деревьями, за счёт чего снизим дисперсию итоговой модели. Такой алгоритм назвывается **случайным лесом** (Random Forest).\n",
    "\n",
    "По сравнению с единичным деревом к параметрам случайного леса добавляются:\n",
    "- `max_features` – число признаков, на основе которых проводятся разбиения при построении дерева.\n",
    "- `n_estimators` – число деревьев.\n",
    "\n",
    "\n",
    "Вопрос: Как можно задать `max_features`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-bundle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:51:54.113083Z",
     "start_time": "2023-05-10T11:50:53.876014Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# TODO: обучите случайный лес с 20 деревьями, каждое из которых строится без ограничений\n",
    "rf = RandomForestRegressor(max_depth=9, n_estimators=20, n_jobs=4)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# TODO: рассчитайте MSE на тренировочной и тестовой выборках\n",
    "print(f\"MSE on train set: {mean_squared_error(y_train, rf.predict(X_train)):.2f}\")\n",
    "print(f\"MSE on train set: {mean_squared_error(y_test, rf.predict(X_test)):.2f}\")\n",
    "\n",
    "# TODO: выведите среднее смещение и среднюю дисперсию модели на тестовой выборке\n",
    "avg_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "    rf,\n",
    "    np.array(X_train),\n",
    "    np.array(y_train),\n",
    "    np.array(X_test),\n",
    "    np.array(y_test),\n",
    "    loss=\"mse\",\n",
    ")\n",
    "print(f\"Average test loss: {avg_loss:.2f}\")\n",
    "print(f\"Average test bias: {avg_bias:.2f}\")\n",
    "print(f\"Average test variance: {avg_var:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-portuguese",
   "metadata": {},
   "source": [
    "\n",
    "Ошибка на тренировочной выборке увеличилась, а на тестовой — уменьшилась, что означает, что мы добились нашей цели в борьбе с переобученными деревьями!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-appeal",
   "metadata": {},
   "source": [
    "## Особенности случайного леса\n",
    "Много важных свойств леса описал в своём [блоге](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#remarks) Лео Бриман (Leo Breiman), создатель случайного леса. Рассмотрим часть из них.\n",
    "Дополнительно: [статья от основ к практике](https://arxiv.org/pdf/1407.7502)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-mississippi",
   "metadata": {},
   "source": [
    "### Out-of-bag-ошибка\n",
    "\n",
    "Как мы обсудили выше, при построении случайного леса каждое дерево строится на бутстрапированной подвыборке, полученной из исходной обучающей выборки случайным набором с повторениями. В каждую подвыборку, таким образом, часть наблюдений попадет несколько раз, а часть ни разу. \n",
    "\n",
    "Какая вероятность, что семпл не попадет в подвыборку? Пусть в выборке $n$ наблюдений. Тогда вероятность семпла попасть в выборку с повторениями 1 раз - $1/n$. Не попасть - $1 - 1/n$. Бутстрап строит подвыборку размера n. Вероятность не попасть в подвыборку n раз тогда - $(1 - 1/n)^n$. Оценим асимптотику. При $ \\lim_{n -> \\inf}{(1 - 1/n)^n}$ сводится к замечательному пределу $(1 + 1/u)^u -> e $. \n",
    "В результате получаем $1/e \\approx 0.37$.\n",
    "\n",
    "А это значит, что мы можем получить оценку качества модели **бесплатно**! В случае MSE мы можем использовать MSE, а точности - error rate. Такая оценка называется **out-of-bag-ошибкой**. \n",
    "\n",
    "То, как конкретно она считается, зависит от реализации, но в целом алгоритм следующий: \n",
    "- Для каждого out-of-bag примера находим все модели, которые на нем не обучались.\n",
    "- Голосованием определяем значение предсказание этих моделей. Считаем соответствующую оценку\n",
    "- Считаем среднюю оценку на всех таких семплах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-california",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:52:44.771132Z",
     "start_time": "2023-05-10T11:52:43.162809Z"
    }
   },
   "outputs": [],
   "source": [
    "# oob_score_ = R2 на невиденных наблюдениях\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=123, oob_score=True, n_jobs=4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70cca8-fd3e-488e-a567-6066cda9d6c4",
   "metadata": {},
   "source": [
    "Вопрос: как OOB ошибка связана с оценкой на кросс-валидации?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa63791-cb0f-417a-b3f5-d89988d06fae",
   "metadata": {},
   "source": [
    "Важно: при небольшом количестве деревьев оценка будет неточной. \n",
    "\n",
    "**Задание:** постройте график зависимости OOB ошибки для количества деревьев и их глубины."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-evening",
   "metadata": {},
   "source": [
    "### 3.3. Важность признаков\n",
    "Как и решающие деревья, случайный лес позволяет оценивать важность признаков. Важность признаков можно оценивать, например, с помощью\n",
    "**Gini Importance**.\n",
    "Для одного дерева: при каждом разбиении по некоторому признаку, считаем Impurity decrease, взвешиваем по числу семплов в сплите и сохраняем результат. В конце суммируем.\n",
    "Лес расширяет эту оценку: считается среднее важности признака по всем деревьям.\n",
    "Однако тогда мы сталкиваемся с такой проблемой, что приоритет отдается признакам с большим числом уровней.\n",
    "\n",
    "Более правильный способ (но и более затратный) -  **Permurtation importance**.\n",
    "Для каждого дерева берется OOB семпл и считается количество голосов, отданных за правильный класс. Далее случайным образом перемешиваются значения переменной m в OOB и количество голосов, отданных за правильный класс, пересчитиывается.Далее одно вычитается из другого. Среднее  значение этой разницы по всем деревьям в лесу является необработанной оценкой важности для переменной m. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-monitor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:52:44.862097Z",
     "start_time": "2023-05-10T11:52:44.778753Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(california[\"feature_names\"], rf.feature_importances_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-breeding",
   "metadata": {},
   "source": [
    "Однако такие оценки опасны в случае коррелирующих признаков. Посмотрим, что произойдёт с важностью, если добавить в выборку линейно зависимый признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-burner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:52:44.865208Z",
     "start_time": "2023-05-10T11:52:44.863222Z"
    }
   },
   "outputs": [],
   "source": [
    "RM_mc = np.array((X_train.iloc[:, 5] * 2 + 3)).reshape(-1, 1)\n",
    "X_train_new = np.hstack((X_train, RM_mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01cb52-e30d-453d-a75e-0c0806f1a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_mc = np.array((X_train.iloc[:, 5] * X_train.iloc[:, 6])).reshape(-1, 1)\n",
    "X_train_new = np.hstack((X_train, RM_mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-slovakia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:52:46.662664Z",
     "start_time": "2023-05-10T11:52:44.866029Z"
    }
   },
   "outputs": [],
   "source": [
    "rf.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-mechanism",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T11:52:46.743774Z",
     "start_time": "2023-05-10T11:52:46.664943Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "names = list(california[\"feature_names\"])\n",
    "names.append(\"_AveOccup\")\n",
    "plt.bar(names, rf.feature_importances_);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-absence",
   "metadata": {},
   "source": [
    "Важности перераспределились между линейной зависимыми признаками `AveOccup` и `_AveOccup`.  Поэтому такая оценка не обязательно четко отражает действительность. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64a528-4e49-47a3-94fd-06a5e66e8d6b",
   "metadata": {},
   "source": [
    "**Задание**: Посчитайте важности с помощью permutation importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977992b-576c-4c64-ad94-32330209aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1602a-12e4-4223-bd6f-663d594ef9dc",
   "metadata": {},
   "source": [
    "## Границы разбиения\n",
    "Рассмотрим также и границы принятия решений. То, как они будут выглядеть, становится довольно тривиальным вопросом, однако все равно построим их, чтобы полностью прочуствовать то, как работает RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e0a19-4df4-49ba-9bca-08e980e5d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 12142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56315699-5942-432b-a2fd-b07219f0050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'/'+\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ec2cf-9921-4366-adf7-94af7c59d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major = df[df[\"quality\"].isin([5,6])]\n",
    "print(\"Length of filtered data is\", len(df_major))\n",
    "X = df_major.drop('quality', axis=1)\n",
    "y = df_major['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ce126-0d9b-4aa1-bb65-3b0d0e9fc059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(\n",
    "        classifier, data: pd.DataFrame, features: list[str], y: pd.DataFrame | pd.Series | None = None\n",
    ") -> None:\n",
    "    # Plotting the tree boundaries\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        classifier,\n",
    "        data.loc[:, features],\n",
    "        response_method=\"predict_proba\",\n",
    "        xlabel=features[0], ylabel=features[1],\n",
    "        alpha=0.5,\n",
    "        cmap=plt.cm.coolwarm,\n",
    "        grid_resolution=500\n",
    "    )\n",
    "\n",
    "    # Plotting the data points\n",
    "    # your code. You can use disp.ax_ to access the axis\n",
    "    disp.ax_.scatter(\n",
    "        data.loc[:, features[0]], data.loc[:, features[1]], c=y, edgecolor=\"k\",cmap=plt.cm.coolwarm\n",
    "    )\n",
    "    plt.title(f\"Decision surface for {classifier.__class__.__name__} trained on {features[0]} and {features[1]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1669d06d-0a9a-474e-b84a-27ac66a4206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the first 2 columns for the plot\n",
    "features = ['volatile acidity', 'alcohol' ]\n",
    "X_train_cols = X_train.loc[:, features ]\n",
    "# Creating and fitting the tree classifier\n",
    "classifier = RandomForestClassifier().fit(X_train_cols, y_train) # your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0ac3d-e052-482f-aeff-7f0e15b9bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_boundary(classifier, data=X_train, features=features, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559250f-20b9-4ea2-afa5-2153ae8bab7d",
   "metadata": {},
   "source": [
    "Отличается ли поверхность для тестового множества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33ffbe-c730-4438-8567-d09d518857f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cols = X_test.loc[:, features ]\n",
    "plot_boundary(classifier, data=X_test_cols, features=features, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f50a2-5cb5-47be-b727-8bf77cf06e0a",
   "metadata": {},
   "source": [
    "Задание: сделайте то же самое для одного дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0be74-c745-4602-afaf-abd8c9caa9f1",
   "metadata": {},
   "source": [
    "## Нестабильность\n",
    "Рассмотрим, как деревья реагируют на случайности в данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726c8a0-168a-4d09-8045-8bc2e6cfdd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=123)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37933cd6-9b1c-49e1-b933-2ef9122cab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fce0c4-ef3b-4db0-a6d4-c5234e3974b3",
   "metadata": {},
   "source": [
    "**Задание:** Постройте границы разбиения для пары сидов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f1f17-1d54-4b16-a1c7-705925c0f790",
   "metadata": {},
   "source": [
    "Проверим теперь, насколько нестабильны случайные леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47a6e0-aaa2-4ca7-bd4a-4553dc482494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=21233)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3caa2-e492-4d85-bdb7-3086a83f60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score is: \", model.score(X_train, y_train))\n",
    "print(\"Test score is: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4cb25-a398-4342-ba81-0a94ca0507e2",
   "metadata": {},
   "source": [
    "**Задание:** Перебирая сиды, оцените разброс по точности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff91ad9-332b-4829-839d-29fb87a9f860",
   "metadata": {},
   "source": [
    "## Что еще\n",
    "\n",
    "В библиотеке scikit-learn есть реализация ExtraTreesClassifier и ExtraTreesRegressor. Данный метод стоит использовать, если вы наблюдаете сильное переобучение на случайном лесе или градиентном бустинге.\n",
    "\n",
    "Случайный лес не очень хорошо работает для сильно разреженных данных.\n",
    "\n",
    "Как и одно дерево, RF не умеет экстраполировать.\n",
    "\n",
    "Для данных, включающих категориальные переменные с различным количеством уровней, случайные леса предвзяты в пользу признаков с большим количеством уровней: когда у признака много уровней, дерево будет сильнее подстраиваться именно под эти признаки, так как на них можно получить более высокое значение информативности\n",
    "\n",
    "RF хорошо параллелизуются, поэтому можно ускорить их обучение )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf614468-52be-4513-9855-e7c661d2aed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
