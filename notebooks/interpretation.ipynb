{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3254f2-ffab-45ef-ad7e-5bec209eeea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes, fetch_openml,load_iris,fetch_california_housing\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression, RFE, SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import (\n",
    "RepeatedStratifiedKFold, \n",
    "cross_val_score, \n",
    "train_test_split, \n",
    "GridSearchCV,\n",
    "cross_val_predict, \n",
    "learning_curve, \n",
    "validation_curve)\n",
    "from sklearn.linear_model import LinearRegression,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error,zero_one_loss, roc_auc_score,root_mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_circles, make_moons, make_blobs\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from os.path import join as pjoin\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#sharper plots\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.linear_model import (LogisticRegression, LogisticRegressionCV,\n",
    "                                  SGDClassifier)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f7f9a-162e-4d43-a764-1ab77f2ce476",
   "metadata": {},
   "source": [
    "# LIME\n",
    "Рассмотрим метод LIME (Local Interpretable Model Agnostic explanations), который позволяет построить интерпретацию для некоторого объясняемого объекта x* и его окрестности.\n",
    "Для этого независимо от модели $a(x)$ для объекта вводится его объясняемое представление, и обучается модель $\\hat a(x)$, которая строит предсказания для этих признаков. Чаще всего для этого используются довольно простые представления (например, мешок слов или суперпиксели). \n",
    "Для построения объясняющей модели:\n",
    "1) Строится суррогатная выборка $X_{x*}^l = {(\\hat x_i, y_i)}$ :\n",
    "    1) создается l примеров $\\hat x_i$ путем пертурбации исходных признаков, например, обнуления случайного количества единиц в интерпретируемом представлении $\\hat x*$ объекта для текстов или  картинок. Вопрос, как в примере с текстом проходит обнуление?\n",
    "    3) для каждого $\\hat x_i$ делается переход в исходное пространство \n",
    "    4) получается $y = a(x_i)$\n",
    "\n",
    "2) Обучается объясняющая модель:\n",
    "   $$a_i = argmin_{b \\in B} {\\sum_{x_i} {\\pi_{x*}(x_i)(a(x_i)-b((\\hat x_i))^2+\\sigma(b)}},$$\n",
    "    - $B$ - cемейство объясняющих моделей, $\\sigma(b)$ - ее сложность\n",
    "    - $\\pi_{x*}(x_i)$ - вес объекта, полученный с помощью некоторого ядра\n",
    "В качестве функции ошибки можно использовать и другую какую-то.\n",
    "Пример - разреженные линейные представления (SLE), если использовать квадратичную функцию и $\\sigma(b) = \\infty[||w_b||_0 K]$ (Что за норма такая $||w_b||_0$?). Для интерпретации в таком случае достаточно вывести признаки с ненулевыми весами - так мы увидим, какие слова были использованы как самые \"важные\"\n",
    "\n",
    "В итоге мы получаем довольно неплохую локальную интерпретацию, но глобально она будет, конечно же, не очень.\n",
    "\n",
    "На практике обычно оптимизируется только часть, относящаяся к лоссу, а сложность контролируется за счет регуляризации объясняющей модели или RFE. \n",
    "Как это делается (для регуляризации): Задается большое $\\lambda$, после чего оно постепенно уменьшается, пока не будет достигнуто K признаков с ненулевыми весами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ef0d3-c82f-4b54-8ac7-77c6fe7efb41",
   "metadata": {},
   "source": [
    "Как LIME работает с таблицами?\n",
    "Во-первых, используются исходные признаки, не бинарные представления.\n",
    "Во-вторых, выборки строятся путем вытягивания значения из нормального распределения со средним и стандартным отклонением, полуенными из обучающего набора для каждой фичи независимо.\n",
    "Кажется, что это не поможет нам строить интерпретацию для конкретного семпла. Но это работает, по крайней мере, частично. Вопрос: почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07c10f-8eb8-4a38-baf3-0845719bf696",
   "metadata": {},
   "source": [
    "## Таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fafb8-cc2f-49cb-abba-9a35b3a49958",
   "metadata": {},
   "source": [
    "Для демонстрации используем уже знакомый нам датасет про дома"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc5207-382d-4599-8331-5732ea31f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\nikol_ri8fhbe\\Documents\\ml\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec230d-e045-4804-a237-210475069f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a230c-9760-43e3-a1ce-9aeae8fb0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(pjoin(data_path, \"realestate.txt\"), sep=\"\\t\")\n",
    "data.fillna(data.median(), inplace=True)\n",
    "X = data.drop(\"SalePrice\", axis=1)\n",
    "y = data[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf813c-2fcd-4231-9894-b7a2d310f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean(), y.min(), y.max(), y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e921151-84b7-4c0a-9f8c-dcd820134630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d32a7dc-0b48-4bf5-8b97-1db456d3d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = # Обучите случайный лес \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6234d-aa46-42a9-a501-57375efb5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d37389-7a77-4946-bf1f-3876b3f1ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)\n",
    "root_mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525bac4-1804-4f9b-9c52-89db1e3bf566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c3e12-e5ae-4fdd-94f7-36119695f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.values.tolist(),\n",
    "                                                  class_names=['SalePrice'], verbose=True, mode='regression', discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59cff5-43a7-4e80-908c-b7417b978dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 5\n",
    "exp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffe7dc-927b-4b34-add1-3c76ded37f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91995762-c8bf-44e4-817f-ada833baaa61",
   "metadata": {},
   "source": [
    "Здесь положительное влияние показано справа, отрицательное - слева. Значения соответствуют весам линейной модели, аппроксимирующей наш случайный лес. Грубо говоря, если мы уменьшим year на 12, то и наше предсказание уменьшится на 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90277f86-336f-4b5f-bb18-dee2505d9d79",
   "metadata": {},
   "source": [
    "Проверим, так ли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a21444-1741-441c-afa4-1f31e3b7205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.values[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecfd60-ec77-4c52-9aa5-2c6a51f82488",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original prediction:', model.predict(X_test.values[j].reshape(1, -1)))\n",
    "tmp = X_test.values[j].copy()\n",
    "tmp[6] = 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650b34c-ec33-4c0b-8dae-511dfdff1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction removing some features:',  model.predict(tmp.reshape(1, -1)))\n",
    "print('Difference:', model.predict(tmp.reshape(1, -1)) - model.predict(X_test.values[j].reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fbea3-9280-4e2c-8331-5f5b45c13f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c16ba-e270-4eed-879c-36a0b29b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559bc9c-341d-453a-b937-73b6a6251b0c",
   "metadata": {},
   "source": [
    "Интересно, что для категориальных фичей мы снова можем построить более удачные объяснения. Как мы поняли, LIME требует бинарные представления. Как мы можем к ним придти? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63862b9-23b4-4b90-acd3-3b17378aab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd367a-85e2-42b1-b00d-6640cd599361",
   "metadata": {},
   "source": [
    "Мы можем задать, какие фичи у нас категориальные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5e694-5dde-41e5-afff-01464905ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"Beds\", \"Baths\", \"Air\", \"Garage\", \"Pool\", \"Quality\", \"Style\", \"Highway\"]\n",
    "categorical_feature_ids = [1,2,3,4,5,7,8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c8e0ed-e85e-4460-a802-11e2b5847909",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values, \n",
    "    feature_names=X_train.columns.values.tolist(),\n",
    "    class_names=['SalePrice'], \n",
    "    categorical_features=categorical_feature_ids,\n",
    "    categorical_names=categorical_features,\n",
    "    verbose=True,\n",
    "    mode='regression', \n",
    "    discretize_continuous=True\n",
    ")\n",
    "# Объясните тот же пример"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab72e9-8836-48a2-b4d9-73157eab4a08",
   "metadata": {},
   "source": [
    "Можно вообще извратиться и сделать за LIME бинаризацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffabc7-f6bc-450d-aa1a-daedfeb0af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = # Бинаризуйте выбранные фичи с помощью sklearn-совместимого энкодера. Названия можно получить через get_feature_names_out()\n",
    "cat_df = # your code\n",
    "X_train_ohe = pd.concat([X_train[[\"SqFeet\",\"Year\", \"Lot\"]], cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ef530-6706-427c-af30-71d4a812d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fc997-8e84-45b0-a5f0-5e59c72fec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = # your code\n",
    "X_test_ohe = pd.concat([X_test[[\"SqFeet\",\"Year\", \"Lot\"]], cat_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b4e20-0697-40a2-af36-28737189bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4713a-dc02-4a53-b1fa-79c072a78266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train_ohe, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbe092-c89a-49d2-93ce-728c88cc026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = # Настройте explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3d592-512e-4150-a45e-e616fba53e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте интерпретацию для 5 семпла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2887d8d-8f59-4f4f-ba7b-5c8f8965eb69",
   "metadata": {},
   "source": [
    "Мы можем также задать ширину ядра и его вид.\n",
    "\n",
    "**Задание**: Напишите свои ядра, берущие на вход расстояния и возвращающие значения от 0 до 1. Замените ядро по умолчанию. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d2ade-ac0c-454d-9036-1867834f51eb",
   "metadata": {},
   "source": [
    "## Тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c42e68-4279-4ce3-8694-ccbee28c6bdb",
   "metadata": {},
   "source": [
    "Также рассмотрим интерпретацию для классификации новостей на две группы - атеизм и христианство."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d44529-f305-474a-b692-f5812559f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04012b8d-d54a-4ed4-bca2-78b7643ad341",
   "metadata": {},
   "source": [
    "Векторизуем тексты с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a0f5f-4932-4cf3-a09b-ff96337bcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_vectors = # сделайте то же самое и для теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd50e5-9bba-4e89-81ac-db3e4cfe50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = # Обучите случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc27f4-305d-42f6-8b4d-b7e983b77533",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(test_vectors)\n",
    "f1_score(newsgroups_test.target, pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c744801-67fb-4f73-bc8c-e6fe9ee2bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3532515-d9cf-41e6-acd0-206c18404041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.predict_proba([newsgroups_test.data[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e91dc-244e-40cc-93ca-eec3d5fc2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1ebaa-2a80-42f6-b765-89dbe657e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 83\n",
    "exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
    "print('True class: %s' % class_names[newsgroups_test.target[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c45632-751d-4c2c-b84c-901ec7c3d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7bb897-d163-4486-9119-5d161df9dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d08a5b-147c-472d-8546-4010c62fb720",
   "metadata": {},
   "source": [
    "Посмотрим, сохраняется ли ситуация с изменением фичей. Тут ожидание следующее - вероятность увеличится на 0.27, если мы уберем из текста слова Host и Posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a81790-54f8-44ee-a424-9039fe7c6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n",
    "tmp = test_vectors[idx].copy()\n",
    "tmp[0,vectorizer.vocabulary_['Posting']] = 0\n",
    "tmp[0,vectorizer.vocabulary_['Host']] = 0\n",
    "print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n",
    "print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12941cf0-d364-4ede-b375-384613bc7bd7",
   "metadata": {},
   "source": [
    "Для текстов мы можем еще и посмотреть на самые важные слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2e951-47e5-4852-b712-6f170652b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064084c9-5eba-47ad-bec6-894829b362fe",
   "metadata": {},
   "source": [
    "Судя по всему, на самом деле моделька смотрит на мусор типа заголовков или частых слов. Проверим, так ли это для какого-то другого примера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b48a1-6e62-4746-82dd-bdc4b30d3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 34\n",
    "exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
    "print('True class: %s' % class_names[newsgroups_test.target[idx]])\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da604c7c-4f84-4a6c-88b9-8593d81664f2",
   "metadata": {},
   "source": [
    "# Итого\n",
    "Плюсы: \n",
    "- Можно поменять предсказывающую модель, но все еще использовать ту же объясняющую\n",
    "- Легко применить, работает с разными видами данных\n",
    "  \n",
    "Минусы:\n",
    "- Для табличных данных очень сложно выбрать ядро, да и вообще выбор ядра может значительно поменять интерпретацию.\n",
    "- Сложность объяснения должна быть выбрана заранее\n",
    "- Нестабильный"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e91d1-11c3-4b2b-b6e7-7da9d9a4baa1",
   "metadata": {},
   "source": [
    "**Задание(*):**\n",
    "У вас есть все составляющие LIME - ядра, алгоритм, кодировка фичей, loess с прошлой пары. Не хватает только кода с семплированием.\n",
    "Напишите свой класс Lime для регрессии и таблиц, который с помощью линейной регрессии и заданного ядра строит интерпретацию. В качестве сложности используйте способ с регуляризацией (можете LARS). При вызове он должен вернуть коэффициенты регрессии, использованные для интерпретации. Не забудьте отшкалиировать фичи. В качестве метрики используйте евклидову.\n",
    "Сделайте упрощенное семплирование - только нормальное распределение и дискретное по частотности категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0273e33-0ab3-46db-b1b1-09c69a1d8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIME:\n",
    "    def __init__(self, train_df, kernel, kernel_width, categorical_features=None):\n",
    "        pass\n",
    "\n",
    "    def _generate_sample(self, instance):\n",
    "        pass\n",
    "        \n",
    "    def explain(self, instance, prediction, num_features=5):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a40d8-143e-427b-b3ec-d20856c50a15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
